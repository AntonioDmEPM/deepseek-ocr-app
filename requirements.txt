flask==3.0.0
werkzeug==3.0.1
torch==2.6.0
transformers==4.48.1
pillow==10.2.0
flash-attn==2.7.3

# Note: You may need to install PyTorch with CUDA support separately:
# pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# For vLLM support (optional, for production deployment):
# vllm==0.8.5
